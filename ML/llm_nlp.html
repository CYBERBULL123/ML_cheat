<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>LLM & NLP Cheat Sheet</title>
  <!-- Bootstrap CSS -->
  <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/css/bootstrap.min.css" rel="stylesheet">
  <!-- Font Awesome Icons -->
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css" rel="stylesheet">
  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&family=Orbitron:wght@500&display=swap" rel="stylesheet">
  <!-- MathJax for LaTeX rendering -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <!-- Custom CSS -->
  <link href="../static/style.css" rel="stylesheet">
  <script src="../static/script.js"></script>
</head>
<body class="dark-mode">
    <div class="dark-mode-toggle">
        <button class="toggle-btn" onclick="toggleTheme()">
          <i class="fas fa-moon"></i> Toggle Theme
        </button>
    </div>

  <!-- Header -->
  <div class="header">
    <h1>LLM & NLP Cheat Sheet</h1>
    <p>A comprehensive guide to Large Language Models (LLMs) and Natural Language Processing (NLP).</p>
  </div>

  <!-- Container -->
  <div class="container my-5">
    <!-- Cheat Sheet Topics -->
    <h2 class="section-title">Cheat Sheet Topics</h2>
    <div class="row">
      <!-- Tokenization -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('tokenization')">
          <div class="card-body">
            <h5 class="card-title">Tokenization</h5>
            <p class="card-text">Breaking text into smaller units (tokens).</p>
          </div>
        </div>
      </div>
      <!-- Embeddings -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('embeddings')">
          <div class="card-body">
            <h5 class="card-title">Embeddings</h5>
            <p class="card-text">Numerical representations of words or sentences.</p>
          </div>
        </div>
      </div>
      <!-- Transformers -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('transformers')">
          <div class="card-body">
            <h5 class="card-title">Transformers</h5>
            <p class="card-text">Neural networks with self-attention mechanisms.</p>
          </div>
        </div>
      </div>
      <!-- GPT -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('gpt')">
          <div class="card-body">
            <h5 class="card-title">GPT</h5>
            <p class="card-text">Generative Pre-trained Transformer.</p>
          </div>
        </div>
      </div>
      <!-- BERT -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('bert')">
          <div class="card-body">
            <h5 class="card-title">BERT</h5>
            <p class="card-text">Bidirectional Encoder Representations from Transformers.</p>
          </div>
        </div>
      </div>
      <!-- T5 -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('t5')">
          <div class="card-body">
            <h5 class="card-title">T5</h5>
            <p class="card-text">Text-to-Text Transfer Transformer.</p>
          </div>
        </div>
      </div>
      <!-- Attention Mechanism -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('attention')">
          <div class="card-body">
            <h5 class="card-title">Attention Mechanism</h5>
            <p class="card-text">Self-Attention, Transformers.</p>
          </div>
        </div>
      </div>
      <!-- Sequence-to-Sequence Models -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('seq2seq')">
          <div class="card-body">
            <h5 class="card-title">Sequence-to-Sequence Models</h5>
            <p class="card-text">Encoder-Decoder architectures.</p>
          </div>
        </div>
      </div>
      <!-- Word2Vec -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('word2vec')">
          <div class="card-body">
            <h5 class="card-title">Word2Vec</h5>
            <p class="card-text">Word embeddings using CBOW and Skip-Gram.</p>
          </div>
        </div>
      </div>
      <!-- GloVe -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('glove')">
          <div class="card-body">
            <h5 class="card-title">GloVe</h5>
            <p class="card-text">Global Vectors for Word Representation.</p>
          </div>
        </div>
      </div>
      <!-- FastText -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('fasttext')">
          <div class="card-body">
            <h5 class="card-title">FastText</h5>
            <p class="card-text">Word embeddings with subword information.</p>
          </div>
        </div>
      </div>
      <!-- RNNs -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('rnns')">
          <div class="card-body">
            <h5 class="card-title">RNNs</h5>
            <p class="card-text">Recurrent Neural Networks for sequential data.</p>
          </div>
        </div>
      </div>
      <!-- LSTMs -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('lstms')">
          <div class="card-body">
            <h5 class="card-title">LSTMs</h5>
            <p class="card-text">Long Short-Term Memory networks.</p>
          </div>
        </div>
      </div>
      <!-- GRUs -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('grus')">
          <div class="card-body">
            <h5 class="card-title">GRUs</h5>
            <p class="card-text">Gated Recurrent Units.</p>
          </div>
        </div>
      </div>
      <!-- Sentiment Analysis -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('sentiment')">
          <div class="card-body">
            <h5 class="card-title">Sentiment Analysis</h5>
            <p class="card-text">Analyzing text sentiment (positive, negative, neutral).</p>
          </div>
        </div>
      </div>
      <!-- Machine Translation -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('translation')">
          <div class="card-body">
            <h5 class="card-title">Machine Translation</h5>
            <p class="card-text">Translating text from one language to another.</p>
          </div>
        </div>
      </div>
      <!-- Text Summarization -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('summarization')">
          <div class="card-body">
            <h5 class="card-title">Text Summarization</h5>
            <p class="card-text">Generating concise summaries of long texts.</p>
          </div>
        </div>
      </div>
      <!-- Named Entity Recognition (NER) -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('ner')">
          <div class="card-body">
            <h5 class="card-title">Named Entity Recognition (NER)</h5>
            <p class="card-text">Identifying entities in text (e.g., names, dates).</p>
          </div>
        </div>
      </div>
      <!-- Question Answering -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('qa')">
          <div class="card-body">
            <h5 class="card-title">Question Answering</h5>
            <p class="card-text">Answering questions based on context.</p>
          </div>
        </div>
      </div>
      <!-- Text Generation -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('textgen')">
          <div class="card-body">
            <h5 class="card-title">Text Generation</h5>
            <p class="card-text">Generating human-like text using LLMs.</p>
          </div>
        </div>
      </div>
      <!-- Chatbots -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('chatbots')">
          <div class="card-body">
            <h5 class="card-title">Chatbots</h5>
            <p class="card-text">Building conversational AI systems.</p>
          </div>
        </div>
      </div>
      <!-- Pre-training and Fine-tuning -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('pretraining')">
          <div class="card-body">
            <h5 class="card-title">Pre-training & Fine-tuning</h5>
            <p class="card-text">Training LLMs on large datasets and adapting them to specific tasks.</p>
          </div>
        </div>
      </div>
      <!-- Transfer Learning -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('transfer')">
          <div class="card-body">
            <h5 class="card-title">Transfer Learning</h5>
            <p class="card-text">Leveraging pre-trained models for new tasks.</p>
          </div>
        </div>
      </div>
      <!-- Prompt Engineering -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('prompt')">
          <div class="card-body">
            <h5 class="card-title">Prompt Engineering</h5>
            <p class="card-text">Designing effective prompts for LLMs.</p>
          </div>
        </div>
      </div>
      <!-- Few-Shot Learning -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('fewshot')">
          <div class="card-body">
            <h5 class="card-title">Few-Shot Learning</h5>
            <p class="card-text">Training models with minimal examples.</p>
          </div>
        </div>
      </div>
      <!-- Zero-Shot Learning -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('zeroshot')">
          <div class="card-body">
            <h5 class="card-title">Zero-Shot Learning</h5>
            <p class="card-text">Performing tasks without explicit training.</p>
          </div>
        </div>
      </div>
      <!-- Reinforcement Learning with Human Feedback (RLHF) -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('rlhf')">
          <div class="card-body">
            <h5 class="card-title">RLHF</h5>
            <p class="card-text">Improving LLMs using human feedback.</p>
          </div>
        </div>
      </div>
      <!-- Model Compression -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('compression')">
          <div class="card-body">
            <h5 class="card-title">Model Compression</h5>
            <p class="card-text">Reducing model size (e.g., pruning, quantization).</p>
          </div>
        </div>
      </div>
      <!-- Multimodal Models -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('multimodal')">
          <div class="card-body">
            <h5 class="card-title">Multimodal Models</h5>
            <p class="card-text">Models that process text, images, and more.</p>
          </div>
        </div>
      </div>
      <!-- Retrieval-Augmented Generation (RAG) -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('rag')">
          <div class="card-body">
            <h5 class="card-title">RAG</h5>
            <p class="card-text">Combining retrieval and generation for better answers.</p>
          </div>
        </div>
      </div>
      <!-- Chain-of-Thought Prompting -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('cot')">
          <div class="card-body">
            <h5 class="card-title">Chain-of-Thought</h5>
            <p class="card-text">Encouraging step-by-step reasoning in LLMs.</p>
          </div>
        </div>
      </div>
      <!-- Bias and Fairness -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('bias')">
          <div class="card-body">
            <h5 class="card-title">Bias and Fairness</h5>
            <p class="card-text">Addressing biases in LLMs.</p>
          </div>
        </div>
      </div>
      <!-- Hallucination Mitigation -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('hallucination')">
          <div class="card-body">
            <h5 class="card-title">Hallucination Mitigation</h5>
            <p class="card-text">Reducing incorrect or fabricated outputs.</p>
          </div>
        </div>
      </div>
      <!-- Model Evaluation -->
      <div class="col-md-4">
        <div class="card" onclick="openPopup('evaluation')">
          <div class="card-body">
            <h5 class="card-title">Model Evaluation</h5>
            <p class="card-text">Metrics for evaluating LLMs (e.g., BLEU, ROUGE).</p>
          </div>
        </div>
      </div>
    </div>
  </div>

  <!-- Popups -->
  <div id="tokenization" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Tokenization</h2>
    <p><strong>Tokenization:</strong> Breaking text into smaller units (tokens) like words, subwords, or characters.</p>
  
    <p><strong>Types:</strong></p>
    <ul>
      <li><strong>Word:</strong> "Hello world" → ["Hello", "world"]</li>
      <li><strong>Subword:</strong> "unhappiness" → ["un", "happiness"]</li>
      <li><strong>Character:</strong> "NLP" → ["N", "L", "P"]</li>
    </ul>
  
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Input raw text.</li>
      <li>Split into tokens using a tokenizer.</li>
      <li>Process tokens for NLP tasks.</li>
    </ol>
  </div>
  
  <div id="embeddings" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Embeddings</h2>
    <p><strong>Definition:</strong> Embeddings are numerical representations of words or sentences in a continuous vector space.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Word2Vec:</strong> Represents words as vectors.</li>
      <li><strong>BERT Embeddings:</strong> Contextual embeddings for words.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Input tokens.</li>
      <li>Convert tokens into embeddings using a pre-trained model.</li>
      <li>Use embeddings for tasks like similarity analysis or classification.</li>
    </ol>
  </div>
  
  <div id="transformers" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Transformers</h2>
    <p><strong>Definition:</strong> Transformers are neural network architectures that use self-attention mechanisms to process sequential data.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>BERT:</strong> Bidirectional transformer for understanding context.</li>
      <li><strong>GPT:</strong> Autoregressive transformer for text generation.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Input sequence of tokens.</li>
      <li>Apply self-attention to capture context.</li>
      <li>Generate output (e.g., text, classification).</li>
    </ol>
  </div>
  
  <div id="gpt" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>GPT (Generative Pre-trained Transformer)</h2>
    <p><strong>Definition:</strong> GPT is an autoregressive LLM designed for text generation and understanding.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>GPT-3:</strong> Generates human-like text for chatbots and content creation.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Input a prompt.</li>
      <li>Generate text token by token using the model.</li>
      <li>Output the generated text.</li>
    </ol>
  </div>
  
  <div id="bert" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>BERT (Bidirectional Encoder Representations from Transformers)</h2>
    <p><strong>Definition:</strong> BERT is a transformer-based model designed for bidirectional context understanding.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Question Answering:</strong> Extracts answers from a given context.</li>
      <li><strong>Sentiment Analysis:</strong> Determines the sentiment of a text.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Input a sequence of tokens.</li>
      <li>Apply bidirectional attention to understand context.</li>
      <li>Output predictions (e.g., answers, sentiment).</li>
    </ol>
  </div>
  
  <div id="t5" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>T5 (Text-to-Text Transfer Transformer)</h2>
    <p><strong>Definition:</strong> T5 treats every NLP task as a text-to-text problem.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Translation:</strong> Converts text from one language to another.</li>
      <li><strong>Summarization:</strong> Generates concise summaries of long texts.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Input text for a specific task (e.g., translation).</li>
      <li>Process text using the T5 model.</li>
      <li>Output the transformed text.</li>
    </ol>
  </div>
  
  <div id="attention" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Attention Mechanism</h2>
    <p><strong>Definition:</strong> Attention mechanisms allow models to focus on specific parts of the input sequence when making predictions.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Self-Attention:</strong> Computes attention scores for input sequences.</li>
      <li><strong>Multi-Head Attention:</strong> Uses multiple attention heads to capture different aspects of the input.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Input sequence of tokens.</li>
      <li>Compute attention scores for each token.</li>
      <li>Generate weighted representations of the input.</li>
    </ol>
  </div>
  
  <div id="seq2seq" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Sequence-to-Sequence Models</h2>
    <p><strong>Definition:</strong> Sequence-to-sequence (Seq2Seq) models are used for tasks where the input and output are sequences, such as machine translation.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Encoder-Decoder Architecture:</strong> Encodes the input sequence into a fixed-size context vector, which is then decoded into the output sequence.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Input sequence of tokens.</li>
      <li>Encode the sequence into a context vector.</li>
      <li>Decode the context vector into the output sequence.</li>
    </ol>
  </div>
  
  <div id="word2vec" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Word2Vec</h2>
    <p><strong>Definition:</strong> Word2Vec is a technique for learning word embeddings by predicting surrounding words in a sentence.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>CBOW (Continuous Bag of Words):</strong> Predicts a target word based on its context.</li>
      <li><strong>Skip-Gram:</strong> Predicts context words given a target word.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Input a corpus of text.</li>
      <li>Train the Word2Vec model to learn word embeddings.</li>
      <li>Use embeddings for tasks like word similarity or classification.</li>
    </ol>
  </div>
  
  <div id="glove" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>GloVe (Global Vectors for Word Representation)</h2>
    <p><strong>Definition:</strong> GloVe learns word embeddings by factorizing a word co-occurrence matrix.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Co-occurrence Matrix:</strong> Captures how often words appear together in a corpus.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Input a corpus of text.</li>
      <li>Construct a word co-occurrence matrix.</li>
      <li>Factorize the matrix to learn word embeddings.</li>
    </ol>
  </div>
  
  <div id="rnns" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Recurrent Neural Networks (RNNs)</h2>
    <p><strong>Definition:</strong> RNNs are designed to handle sequential data by maintaining a hidden state that captures information from previous time steps.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Vanilla RNN:</strong> Processes sequences step-by-step.</li>
      <li><strong>GRU (Gated Recurrent Unit):</strong> Improves upon vanilla RNNs with gating mechanisms.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Input sequence of tokens.</li>
      <li>Update hidden state at each time step.</li>
      <li>Generate output based on the final hidden state.</li>
    </ol>
  </div>
  
  <div id="lstms" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Long Short-Term Memory (LSTM)</h2>
    <p><strong>Definition:</strong> LSTMs are a type of RNN that use gating mechanisms to control the flow of information and solve the vanishing gradient problem.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Forget Gate:</strong> Decides what information to discard from the cell state.</li>
      <li><strong>Input Gate:</strong> Decides what new information to store in the cell state.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Input sequence of tokens.</li>
      <li>Update cell state and hidden state using gates.</li>
      <li>Generate output based on the final hidden state.</li>
    </ol>
  </div>
  
  <div id="sentiment" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Sentiment Analysis</h2>
    <p><strong>Definition:</strong> Sentiment analysis determines the sentiment (positive, negative, or neutral) of a text.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Binary Classification:</strong> Classifies text as positive or negative.</li>
      <li><strong>Multi-Class Classification:</strong> Classifies text into multiple sentiment categories.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Input text.</li>
      <li>Tokenize and preprocess the text.</li>
      <li>Use a trained model to predict sentiment.</li>
    </ol>
  </div>
  
  <div id="translation" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Machine Translation</h2>
    <p><strong>Definition:</strong> Machine translation converts text from one language to another.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Neural Machine Translation (NMT):</strong> Uses Seq2Seq models with attention.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Input text in the source language.</li>
      <li>Tokenize and preprocess the text.</li>
      <li>Use a trained model to generate translated text.</li>
    </ol>
  </div>
  
  <div id="summarization" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Text Summarization</h2>
    <p><strong>Definition:</strong> Text summarization generates concise summaries of long texts.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Extractive Summarization:</strong> Selects important sentences from the text.</li>
      <li><strong>Abstractive Summarization:</strong> Generates new sentences to summarize the text.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Input long text.</li>
      <li>Tokenize and preprocess the text.</li>
      <li>Use a trained model to generate a summary.</li>
    </ol>
  </div>
  
  <div id="ner" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Named Entity Recognition (NER)</h2>
    <p><strong>Definition:</strong> NER identifies entities in text (e.g., names, dates, locations).</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Entity Types:</strong> Person, Organization, Location, Date, etc.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Input text.</li>
      <li>Tokenize and preprocess the text.</li>
      <li>Use a trained model to identify entities.</li>
    </ol>
  </div>
  
  <div id="qa" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Question Answering</h2>
    <p><strong>Definition:</strong> Question answering systems answer questions based on a given context.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Extractive QA:</strong> Extracts answers directly from the context.</li>
      <li><strong>Generative QA:</strong> Generates answers based on the context.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Input a question and context.</li>
      <li>Tokenize and preprocess the text.</li>
      <li>Use a trained model to generate an answer.</li>
    </ol>
  </div>
  
  <div id="textgen" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Text Generation</h2>
    <p><strong>Definition:</strong> Text generation models generate human-like text based on a prompt.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>GPT-3:</strong> Generates text for chatbots, content creation, etc.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Input a prompt.</li>
      <li>Tokenize and preprocess the text.</li>
      <li>Use a trained model to generate text.</li>
    </ol>
  </div>
  
  <div id="chatbots" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Chatbots</h2>
    <p><strong>Definition:</strong> Chatbots are conversational AI systems that interact with users in natural language.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Rule-Based Chatbots:</strong> Follow predefined rules.</li>
      <li><strong>AI-Powered Chatbots:</strong> Use NLP models like GPT for dynamic responses.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Input user query.</li>
      <li>Tokenize and preprocess the text.</li>
      <li>Use a trained model to generate a response.</li>
    </ol>
  </div>
  
  <div id="pretraining" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Pre-training & Fine-tuning</h2>
    <p><strong>Definition:</strong> Pre-training involves training a model on a large dataset, while fine-tuning adapts the model to a specific task.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>BERT:</strong> Pre-trained on large text corpora, fine-tuned for tasks like QA or NER.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Pre-train a model on a large dataset.</li>
      <li>Fine-tune the model on a task-specific dataset.</li>
      <li>Evaluate and deploy the model.</li>
    </ol>
  </div>
  
  <div id="transfer" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Transfer Learning</h2>
    <p><strong>Definition:</strong> Transfer learning leverages pre-trained models for new tasks, reducing the need for large datasets.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Fine-Tuning:</strong> Adapting a pre-trained model to a new task.</li>
      <li><strong>Feature Extraction:</strong> Using pre-trained embeddings as input features.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Load a pre-trained model.</li>
      <li>Adapt the model to the new task.</li>
      <li>Train and evaluate the model.</li>
    </ol>
  </div>

  <div id="prompt" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Prompt Engineering</h2>
    <p><strong>Definition:</strong> Designing effective prompts to guide LLMs in generating desired outputs.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Instructional Prompts:</strong> "Translate this text to French."</li>
      <li><strong>Few-Shot Prompts:</strong> Providing examples to guide the model.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Define the task.</li>
      <li>Design a clear and specific prompt.</li>
      <li>Test and refine the prompt.</li>
    </ol>
  </div>

  <div id="fewshot" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Few-Shot Learning</h2>
    <p><strong>Definition:</strong> Training models with minimal examples by leveraging pre-trained knowledge.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Text Classification:</strong> Classifying text with only a few labeled examples.</li>
      <li><strong>Question Answering:</strong> Answering questions with limited context.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Provide a few examples.</li>
      <li>Fine-tune the model or use prompt engineering.</li>
      <li>Evaluate performance.</li>
    </ol>
  </div>

  <div id="zeroshot" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Zero-Shot Learning</h2>
    <p><strong>Definition:</strong> Performing tasks without explicit training by leveraging pre-trained models.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Text Classification:</strong> Classifying text into unseen categories.</li>
      <li><strong>Translation:</strong> Translating text between languages not seen during training.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Define the task.</li>
      <li>Use a pre-trained model with task-specific prompts.</li>
      <li>Evaluate the output.</li>
    </ol>
  </div>

  <div id="rlhf" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Reinforcement Learning with Human Feedback (RLHF)</h2>
    <p><strong>Definition:</strong> Improving LLMs using feedback from humans to align outputs with desired behavior.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Chatbot Training:</strong> Refining responses based on user feedback.</li>
      <li><strong>Content Moderation:</strong> Filtering harmful content using human-labeled data.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Collect human feedback on model outputs.</li>
      <li>Train a reward model using feedback.</li>
      <li>Fine-tune the LLM using the reward model.</li>
    </ol>
  </div>

  <div id="compression" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Model Compression</h2>
    <p><strong>Definition:</strong> Reducing the size of models for efficient deployment.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Pruning:</strong> Removing less important weights.</li>
      <li><strong>Quantization:</strong> Reducing precision of weights (e.g., FP32 to INT8).</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Identify redundant parameters.</li>
      <li>Apply compression techniques.</li>
      <li>Evaluate performance and fine-tune.</li>
    </ol>
  </div>

  <div id="multimodal" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Multimodal Models</h2>
    <p><strong>Definition:</strong> Models that process multiple modalities (e.g., text, images, audio).</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>CLIP:</strong> Connects text and images.</li>
      <li><strong>Flamingo:</strong> Processes text and images for visual question answering.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Input multiple modalities (e.g., text and image).</li>
      <li>Process using a multimodal architecture.</li>
      <li>Generate combined outputs.</li>
    </ol>
  </div>

  <div id="rag" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Retrieval-Augmented Generation (RAG)</h2>
    <p><strong>Definition:</strong> Combining retrieval and generation for better answers.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Question Answering:</strong> Retrieving relevant documents and generating answers.</li>
      <li><strong>Chatbots:</strong> Enhancing responses with external knowledge.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Retrieve relevant documents.</li>
      <li>Generate answers using the retrieved context.</li>
      <li>Evaluate and refine.</li>
    </ol>
  </div>

  <div id="cot" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Chain-of-Thought Prompting</h2>
    <p><strong>Definition:</strong> Encouraging step-by-step reasoning in LLMs for complex tasks.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Math Problems:</strong> Breaking down problems into steps.</li>
      <li><strong>Logical Reasoning:</strong> Solving puzzles with intermediate reasoning.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Provide a problem.</li>
      <li>Prompt the model to think step-by-step.</li>
      <li>Evaluate the reasoning process.</li>
    </ol>
  </div>

  <div id="bias" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Bias and Fairness</h2>
    <p><strong>Definition:</strong> Addressing biases in LLMs to ensure fair and ethical outputs.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Gender Bias:</strong> Mitigating biased language in text generation.</li>
      <li><strong>Racial Bias:</strong> Ensuring fair treatment across demographics.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Identify biases in model outputs.</li>
      <li>Apply debiasing techniques.</li>
      <li>Evaluate fairness metrics.</li>
    </ol>
  </div>

  <div id="hallucination" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Hallucination Mitigation</h2>
    <p><strong>Definition:</strong> Reducing incorrect or fabricated outputs in LLMs.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>Fact-Checking:</strong> Verifying generated facts against trusted sources.</li>
      <li><strong>Contextual Anchoring:</strong> Grounding outputs in provided context.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Identify hallucinated outputs.</li>
      <li>Implement mitigation strategies (e.g., retrieval, constraints).</li>
      <li>Evaluate and refine.</li>
    </ol>
  </div>

  <div id="evaluation" class="popup">
    <span class="close" onclick="closePopup()">&times;</span>
    <h2>Model Evaluation</h2>
    <p><strong>Definition:</strong> Assessing the performance of LLMs using metrics and benchmarks.</p>
    <p><strong>Examples:</strong></p>
    <ul>
      <li><strong>BLEU:</strong> Evaluating machine translation quality.</li>
      <li><strong>ROUGE:</strong> Measuring text summarization performance.</li>
    </ul>
    <p><strong>Workflow:</strong></p>
    <ol>
      <li>Define evaluation metrics.</li>
      <li>Run the model on test data.</li>
      <li>Analyze and interpret results.</li>
    </ol>
  </div>

  <!-- Back to Main Page -->
    <div class="row mt-4">
        <div class="col-md-12 text-center">
        <a href="../index.html" class="btn btn-primary">
            <i class="fas fa-home"></i> Back to Main Page
        </a>
        </div>
    </div>

  <!-- Add more popups for other topics as needed -->

  <!-- Overlay -->
  <div class="overlay" onclick="closePopup()"></div>

  <!-- Footer -->
  <div class="footer">
    <p>Created by <a href="#">Aditya Pandey</a> | &copy; 2025</p>
  </div>

  <!-- Bootstrap JS -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0-alpha1/dist/js/bootstrap.bundle.min.js"></script>
</body>
</html>